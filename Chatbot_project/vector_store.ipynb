{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 폴더내 PDF 파일을 모두 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple definitions in dictionary at byte 0x41fa7 for key /Type\n",
      "Multiple definitions in dictionary at byte 0x4d794 for key /Type\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성공: 6개의 PDF 파일이 merged.pdf로 병합되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfMerger\n",
    "import os\n",
    "\n",
    "def merge_pdfs(directory_path, output_filename):\n",
    "    # 디렉토리 존재 여부 확인\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"오류: 디렉토리가 존재하지 않습니다: {directory_path}\")\n",
    "        return\n",
    "    \n",
    "    # PDF 병합을 위한 객체 생성\n",
    "    merger = PdfMerger()\n",
    "    \n",
    "    # 디렉토리 내의 모든 PDF 파일 찾기\n",
    "    pdf_files = [f for f in os.listdir(directory_path) if f.endswith('.pdf')]\n",
    "    \n",
    "    # PDF 파일 존재 여부 확인\n",
    "    if not pdf_files:\n",
    "        print(\"오류: 지정된 폴더에 PDF 파일이 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # 각 PDF 파일을 병합\n",
    "        for pdf in pdf_files:\n",
    "            file_path = os.path.join(directory_path, pdf)\n",
    "            merger.append(file_path)\n",
    "        \n",
    "        # 병합된 PDF 저장\n",
    "        with open(output_filename, 'wb') as output_file:\n",
    "            merger.write(output_file)\n",
    "        \n",
    "        print(f\"성공: {len(pdf_files)}개의 PDF 파일이 {output_filename}로 병합되었습니다.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {str(e)}\")\n",
    "    \n",
    "    finally:\n",
    "        merger.close()\n",
    "\n",
    "# 사용 예시\n",
    "directory_path = r\"../Chatbot_project/RAG paper\"  # PDF 파일들이 있는 폴더 경로\n",
    "output_filename = \"merged.pdf\"  # 병합된 PDF 파일명\n",
    "merge_pdfs(directory_path, output_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PDF 파일을 마크다운 형식으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'변환 성공'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from markitdown import MarkItDown\n",
    "def convert_pdf_to_markdown(pdf_path: str, md_out_path: str):\n",
    "    try:\n",
    "        markitdown = MarkItDown()\n",
    "        result = markitdown.convert(pdf_path)\n",
    "        \n",
    "        # text_content 속성 사용\n",
    "        markdown_text = result.text_content\n",
    "        \n",
    "        with open(md_out_path, 'w', encoding='utf-8') as md_file:\n",
    "            md_file.write(markdown_text)\n",
    "            \n",
    "        return \"변환 성공\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"오류 발생: {str(e)}\"\n",
    "\n",
    "convert_pdf_to_markdown(r'../Chatbot_project/merged.pdf', 'RAG.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. vector DB 구현(임베딩은 open ai api 사용 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구현을 선제적으로 확인하기 위해 임시 QA체인을 포함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "답변: 프로이트(Freud)는 심리학자이자 심리학의 창시자로 알려진 사람입니다. 그는 무의식, 성욕 이론, 정신 분석 등의 이론으로 유명합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --------------------------------------\n",
    "# (1) 환경 변수 설정\n",
    "# --------------------------------------\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# --------------------------------------\n",
    "# (2) 마크다운 파일 로드 및 벡터스토어 생성\n",
    "# --------------------------------------\n",
    "def build_vectorstore_from_markdown(md_file_path: str) -> FAISS:\n",
    "    \"\"\"\n",
    "    마크다운 파일을 FAISS 벡터스토어로 변환\n",
    "    \"\"\"\n",
    "    # 마크다운 파일 읽기\n",
    "    with open(md_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        markdown_text = f.read()\n",
    "    \n",
    "    # 텍스트 분할\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "        separator=\"\\n\"\n",
    "    )\n",
    "    docs = text_splitter.split_text(markdown_text)\n",
    "    \n",
    "    if not docs:\n",
    "        raise ValueError(\"문서가 비어 있습니다. 마크다운 파일을 확인하세요.\")\n",
    "    \n",
    "    # OpenAI 임베딩 및 벡터스토어 생성\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_texts(docs, embedding=embeddings)\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "# --------------------------------------\n",
    "# (3) QA 체인 생성\n",
    "# --------------------------------------\n",
    "def create_qa_chain(vectorstore: FAISS) -> RetrievalQA:\n",
    "    \"\"\"\n",
    "    질의응답 체인 생성\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        model_name=\"gpt-3.5-turbo\"\n",
    "    )\n",
    "    \n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vectorstore.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 3}\n",
    "        )\n",
    "    )\n",
    "    return qa_chain\n",
    "\n",
    "# --------------------------------------\n",
    "# (4) 메인 실행 코드\n",
    "# --------------------------------------\n",
    "def main():\n",
    "    # 마크다운 파일 경로\n",
    "    md_path = r\"../Chatbot_project/RAG.md\"\n",
    "    \n",
    "    # 벡터스토어 생성\n",
    "    vectorstore = build_vectorstore_from_markdown(md_path)\n",
    "    \n",
    "    # 벡터스토어 저장\n",
    "    vectorstore.save_local('./db/faiss')\n",
    "    \n",
    "    # QA 체인 생성\n",
    "    qa_chain = create_qa_chain(vectorstore)\n",
    "\n",
    "    # 질문 실행\n",
    "    query = input(\"질문을 입력하세요 : \")    \n",
    "    response = qa_chain.run(query)\n",
    "    print(f\"\\n답변: {response}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
